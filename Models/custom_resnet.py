# -*- coding: utf-8 -*-
"""custom_resnet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1744SAdINnNjmxTqSpYwYpaOp8S5koqpG
"""

import torch
import torch.nn as nn
import torch.nn.functional as F



#Residual block
class ResBlock(nn.Module):
    expansion = 1

    def __init__(self, in_channels, out_channels,stride=1):
        super(ResBlock, self).__init__()
        self.in_channels=in_channels
        self.conv1 = nn.Sequential(
                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),
                        nn.BatchNorm2d(out_channels),
                        nn.ReLU())
        self.conv2= nn.Sequential(
                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),
                        nn.BatchNorm2d(out_channels))
        self.relu=nn.ReLU()
        self.out_channels=out_channels

            

    def forward(self, x):
        residual=x
        out = self.conv1(x)
        out = self.conv2(out)
        out += residual
        out = self.relu(out)
        return out


        

class CustomResNet(nn.Module):
    def __init__(self, ResBlock, num_classes=10):
        super(CustomResNet, self).__init__()
        self.in_channels = 16 
        self.ResBlock1= ResBlock(128,128,stride=1)
        self.ResBlock2=ResBlock(512,512,stride=1)
        #preparation layer
        self.conv1 = nn.Sequential(
                        nn.Conv2d(3, 64, kernel_size = 3, stride = 1, padding = 1),
                        nn.BatchNorm2d(64),
                        nn.ReLU()) # input : 32 * 32 *3 ,output : 32 * 32 *64
        # layer 1
        self.layer1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),
                                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),
                                   nn.BatchNorm2d(128),
                                   nn.ReLU()) # onput : 16 * 16 * 128
        
        # layer 2
        self.layer2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size = 3, stride = 1),
                                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),
                                   nn.BatchNorm2d(256),
                                   nn.ReLU()) # onput : 7 * 7 * 256
        
        # layer 3
        self.layer3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size = 3, stride = 1, padding=1),
                                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),
                                   nn.BatchNorm2d(512),
                                   nn.ReLU()) # output : 4 * 4 * 512
        

        self.maxpool = nn.MaxPool2d(kernel_size = 4) # output : 2 * 2 * 512
        #self.conv=nn.Conv2d(512,10,kernel_size=1,padding=0,stride=2)
        self.fc=nn.Linear(512,num_classes)
        #self.gap = nn.AvgPool2d(4)
        self.classifier = nn.Sequential(nn.MaxPool2d(4), 
                                        nn.Flatten(), 
                                        nn.Linear(512, num_classes))




    def forward(self, x):
        out = self.conv1(x)
        layer1 = self.layer1(out)
        r1 = self.ResBlock1(layer1)
        res1= torch.add(layer1,r1)
        layer2= self.layer2(res1)
        layer3= self.layer3(layer2)
        r2= self.ResBlock2(layer3)
        res2= torch.add(layer3,r2)
        #max= self.maxpool(res2)
        #conv= self.conv(max)
        #gap =  self.gap(conv)
        #max=nn.Flatten(max)
        #max= max.view(max.size(0), -1)
        out=self.classifier(res2)
        #fc=self.fc(max)
        
        
        
        return F.log_softmax(out, dim=-1)